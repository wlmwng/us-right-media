{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68335bc6-08de-4b8d-8fe4-1adae37bebe9",
   "metadata": {},
   "source": [
    "## Softcosine Clusters\n",
    "**Purpose:** Export samples of clusters per similarity threshold to CSV\n",
    "- Convert clusters from .jsonl files into tidy-formatted dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f24d1e5-fcf7-453b-82c9-fe9859e654fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bde01fcb-052e-4204-a0d3-cc9526135aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonl_dir = os.path.join(\"..\", \"..\", \"data\", \"02-intermediate\", \"06-newsevents\", \"05-softcosine-clusters\", \"jsonl\")\n",
    "df_dir = os.path.join(\"..\", \"..\", \"data\", \"02-intermediate\", \"06-newsevents\", \"05-softcosine-clusters\", \"dataframes\")\n",
    "sample_dir = os.path.join(\"..\", \"..\", \"data\", \"02-intermediate\", \"06-newsevents\", \"05-softcosine-clusters-sample\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76f48ea-4456-46be-8c38-71a96d69a3be",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35738b2c-aa13-4199-8cea-47d10ed71a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_clusters(jsonl_file):\n",
    "    \"\"\"Load fetched content from .jsonl file.\n",
    "    \n",
    "    Args:\n",
    "        jsonl_file (str): path + filename for jsonl file\n",
    "    \n",
    "    Yields:\n",
    "        cluster as JSON stringified object\n",
    "\n",
    "    \"\"\"\n",
    "    with open(file=jsonl_file, mode=\"r\", encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            data = json.loads(line)\n",
    "            yield data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a6c704f-7643-4659-942f-03b3a053f082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_docs(cluster):\n",
    "    \"\"\"Flatten the docs within a cluster\"\"\"\n",
    "    flat_docs = []\n",
    "   \n",
    "    for doc in cluster[\"docs\"]:\n",
    "        d = {}\n",
    "        d[\"cluster_id\"]=cluster[\"cluster_id\"]\n",
    "        d[\"cluster_size\"]=cluster[\"cluster_size\"]\n",
    "        d[\"doc_id\"]=doc[\"_id\"]\n",
    "        d[\"doc_publish_date\"]=doc[\"publish_date\"]\n",
    "        d[\"doc_title\"]=doc[\"title\"]\n",
    "        flat_docs.append(d)\n",
    "\n",
    "    # ensure articles within a cluster are sorted from oldest to newest\n",
    "    flat_docs = sorted(flat_docs, key=lambda k: k[\"doc_publish_date\"], reverse=False)\n",
    "    \n",
    "    return flat_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce08fcf8-3245-4922-83fb-e360edab2f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df(clusters, similarity_threshold, export_pkl=True):\n",
    "    \"\"\"Flatten clusters and return them in a tidy-formatted dataframe. Option to export dataframe to pkl.\"\"\"\n",
    "    dfs = []\n",
    "    for c in clusters:\n",
    "        f = flatten_docs(c)\n",
    "        dfs.append(pd.DataFrame(f))\n",
    "    merged_df = pd.concat(dfs)\n",
    "    merged_df = merged_df.reset_index(drop=True)\n",
    "    \n",
    "    if export_pkl:\n",
    "        merged_df.to_pickle(os.path.join(df_dir, f\"clusters_{similarity_threshold}.pkl\"))\n",
    "        \n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9a7171-8ee3-4777-becd-d9ace367e354",
   "metadata": {},
   "source": [
    "### Export flattened version of clusters for each similarity threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "071ef992-7206-474f-b883-dc25ae7e6ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = {}\n",
    "for n in range(2, 10):\n",
    "    jsonl_file = os.path.join(jsonl_dir, f\"clusters_softcos0{n}.jsonl\")\n",
    "    clusters = [c for c in load_clusters(jsonl_file)]\n",
    "    df = make_df(clusters, f\"softcos0{n}\", export_pkl=True)\n",
    "    df_dict[f\"softcos0{n}\"]=df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c2532a-ec0c-4ed2-b08b-6494c80d575d",
   "metadata": {},
   "source": [
    "### Export samples for each similarity threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "487bab25-5453-46d0-90fd-2c6b0eb3f360",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df_sample(df_dict, similarity_threshold, export_csv=True):\n",
    "    \"\"\"Make a dataframe which contains a sample of multi-article clusters for a particular similarity threshold.\n",
    "    The sample contains 100 clusters. The 10 biggest clusters are always included, and the remaining 90 are randomly chosen.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = df_dict[similarity_threshold]\n",
    "    \n",
    "    # only multi-article clusters are included\n",
    "    df = df.loc[df[\"cluster_size\"]>1]\n",
    "    \n",
    "    # false positives are likelier in large clusters so make sure to check the 10 biggest clusters\n",
    "    df_distinct_ids = df.drop_duplicates(subset=[\"cluster_id\"])\n",
    "    df_distinct_ids = df_distinct_ids.sort_values(by=\"cluster_size\",ascending=False).reset_index(drop=True)\n",
    "    top_ids = list(df_distinct_ids.iloc[0:10][\"cluster_id\"])\n",
    "    other_ids = list(df_distinct_ids.iloc[10:][\"cluster_id\"])\n",
    "    \n",
    "    # sample the other ids\n",
    "    random.seed(42)\n",
    "    sampled_cluster_ids = top_ids + random.sample(other_ids, 5)\n",
    "    sample_ids = [f\"{similarity_threshold}_sample_{n}\" for n, s_id in enumerate(sampled_cluster_ids)]\n",
    "    cluster2sample_ids = dict(zip(sampled_cluster_ids, sample_ids))\n",
    "\n",
    "    df_sample = df.loc[df[\"cluster_id\"].isin(sampled_cluster_ids)].reset_index(drop=True)\n",
    "    df_sample[\"sample_id\"] = df_sample[\"cluster_id\"].map(lambda c: cluster2sample_ids[c])\n",
    "    df_sample[\"cluster_type\"] = \"\"\n",
    "    df_sample[\"doc_misassigned\"] = \"\"\n",
    "    df_sample[\"notes\"] = \"\"\n",
    "    \n",
    "    df_sample[\"sample_order\"] = df_sample[\"sample_id\"].map(lambda s: int(s[s.rfind(\"_\")+1:]))\n",
    "    df_sample = df_sample.sort_values(by=\"sample_order\", ascending=True).reset_index(drop=True)\n",
    "    \n",
    "    # cluster_type: \"newsevent\", \"issue\"\n",
    "    # doc_is_error\n",
    "    df_sample = df_sample[[\"sample_id\", \"cluster_id\", \"cluster_size\",\n",
    "                           \"doc_id\", \"doc_publish_date\",\n",
    "                           \"cluster_type\",\n",
    "                           \"doc_misassigned\", \"notes\",\n",
    "                           \"doc_title\"]]\n",
    "    \n",
    "    if export_csv:\n",
    "        df_sample.to_csv(os.path.join(sample_dir, f\"clusters_{similarity_threshold}_sample.csv\"), index=False)\n",
    "\n",
    "    return df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e55483bd-48f2-4c2a-9658-a4efd17cf814",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(2,10):\n",
    "    make_df_sample(df_dict, f\"softcos0{n}\", export_csv=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (usrightmedia)",
   "language": "python",
   "name": "usrightmedia"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
